{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top\"></a>\n",
    "<div style=\"width:1000 px\">\n",
    "\n",
    "<div style=\"float:right; width:98 px; height:98px;\">\n",
    "<img src=\"https://raw.githubusercontent.com/Unidata/MetPy/master/metpy/plots/_static/unidata_150x150.png\" alt=\"Unidata Logo\" style=\"height: 98px;\">\n",
    "</div>\n",
    "\n",
    "<h1>Advanced Surface Observations: Working with Mesonet Data</h1>\n",
    "<h3>Unidata Python Workshop</h3>\n",
    "\n",
    "<div style=\"clear:both\"></div>\n",
    "</div>\n",
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "<div style=\"float:right; width:250 px\"><img src=\"http://weather-geek.net/images/metar_what.png\" alt=\"METAR\" style=\"height: 200px;\"></div>\n",
    "\n",
    "## Overview:\n",
    "\n",
    "* **Teaching:** 30 minutes\n",
    "* **Exercises:** 35 minutes\n",
    "\n",
    "### Questions\n",
    "1. How do I read in complicated mesonet data with Pandas?\n",
    "1. How do I merge multiple Pandas DataFrames?\n",
    "1. What's the best way to make a station plot of data?\n",
    "1. How can I make a time series of data from one station?\n",
    "\n",
    "### Objectives\n",
    "1. <a href=\"#reading\">Read Mesonet data with Pandas</a>\n",
    "2. <a href=\"#merge\">Merge multiple Pandas DataFrames together </a>\n",
    "3. <a href=\"#plot\">Plot mesonet data with MetPy and CartoPy</a>\n",
    "4. <a href=\"#timeseries\">Create time series plots of station data</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"reading\"></a>\n",
    "# Reading Mesonet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're going to use the Pandas library to read text-based data. Pandas is excellent at handling text, csv, and other files. However, you have to help Pandas figure out how your data is formatted sometimes. Lucky for you, mesonet data frequently comes in forms that are not the most user-friendly. Through this notebook, we'll see how these complicated datasets can be handled nicely by Pandas to create useful station plots for hand analysis or publication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### West Texas Mesonet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [West Texas Mesonet](http://www.depts.ttu.edu/nwi/research/facilities/wtm/index.php) is a wonderful data source for researchers and storm chasers alike! We have some 5-minute observations from the entire network on 22 March 2019 that we'll analyze in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data and handle the lines that cause issues\n",
    "filename = 'West_Texas_data/FIVEMIN_82.txt'\n",
    "tx_data = pd.read_csv(filename, delimiter=',', header=None, error_bad_lines=False, warn_bad_lines=False)\n",
    "tx_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to be understandable\n",
    "tx_data.columns = ['Array_ID', 'QC_flag', 'Time', 'Station_ID', '10m_scalar_wind_speed',\n",
    "                 '10m_vector_wind_speed', '10m_wind_direction',\n",
    "                 '10m_wind_direction_std', '10m_wind_speed_std', \n",
    "                 '10m_gust_wind_speed', '1.5m_temperature', \n",
    "                 '9m_temperature', '2m_temperature', \n",
    "                 '1.5m_relative_humidity', 'station_pressure', 'rainfall', \n",
    "                 'dewpoint', '2m_wind_speed', 'solar_radiation']\n",
    "tx_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The West Texas mesonet provides data on weather, agriculture, and radiation. These different observations are encoded 1, 2, and 3, respectively in the Array ID column. Let's parse out only the meteorological data for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-meteorological rows\n",
    "tx_data = tx_data[tx_data['Array_ID'] == 1]\n",
    "tx_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Station pressure is 600 hPa lower than it should be, so let's correct that as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct presssure \n",
    "tx_data['station_pressure'] += 600\n",
    "tx_data['station_pressure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Time\n",
    "Time is given as HHMM in this file, but it would be great if we have a ```datetime``` object to work with so that time is continue for plotting and not just an array of scalar values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something like this should work but isn't for me\n",
    "# tx_data['Time'] = pd.to_datetime(tx_data['Time'].apply(str), format='%H%d', origin='2019-03-22')\n",
    "tx_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's read in the station metadata file for the West Texas mesonet, so that we can have coordinates to plot data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_stations = pd.read_csv('WestTexas_stations.csv')\n",
    "tx_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oklahoma Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try reading in the Oklahoma Mesonet data located in the `201903222300.mdf` file using Pandas. Check out the documentation on Pandas if you run into issues! Make sure to handle missing values as well. Also read in the Oklahoma station data from the `Oklahoma_stations.csv` file. Only read in the station ID, latitude, and longitude columns from that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/read_ok.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"merge\"></a>\n",
    "# Merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two data files per mesonet - one for the data itself and one for the metadata. It would be really nice to combine these DataFrames together into one for each mesonet. Pandas has some built in methods to do this - see [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html). For this example, we'll be using the `merge` method. First, let's rename columns in the Oklahoma station DataFrame to be more understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns so merging can occur\n",
    "ok_stations.columns = ['STID', 'LAT', 'LON']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conveniently, we have a `STID` column in both DataFrames. Let's base our merge on that and see what we get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two data frames based on the Station ID\n",
    "ok_data = pd.merge(ok_data, ok_stations, on='STID')\n",
    "ok_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was nice! But what if our DataFrames don't have the same column name, and we want to avoid renaming columns? Check out the documentation for `pd.merge` and see how we can merge the West Texas DataFrames together. Also, subset the data to only be from 2300 UTC, which is when our Oklahoma data was taken. Call the new DataFrame `tx_one_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/merge_texas.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"plot\"></a>\n",
    "# Creating a Station Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to plot temperature, dewpoint, and wind barbs. Given our data from the two mesonets, do we have what we need? If not, use MetPy to calculate what you need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/data_conversion.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make a Station Plot with our data using MetPy and CartoPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metpy.plots import StationPlot\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a plot with map features\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "proj = ccrs.Stereographic(central_longitude=-100, central_latitude=35)\n",
    "ax = fig.add_subplot(1, 1, 1, projection=proj)\n",
    "ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='black')\n",
    "ax.gridlines()\n",
    "\n",
    "\n",
    "# Create a station plot pointing to an Axes to draw on as well as the location of points\n",
    "stationplot = StationPlot(ax, ok_data['LON'].values, ok_data['LAT'].values, transform=ccrs.PlateCarree(),\n",
    "                          fontsize=10)\n",
    "stationplot.plot_parameter('NW', ok_data['TAIR'], color='red')\n",
    "stationplot.plot_parameter('SW', ok_dewpoint, color='green')\n",
    "stationplot.plot_barb(ok_u, ok_v)\n",
    "\n",
    "# Texas Data\n",
    "stationplot = StationPlot(ax, tx_one_time['Long'].values, tx_one_time['Lat'].values, transform=ccrs.PlateCarree(),\n",
    "                          fontsize=10)\n",
    "stationplot.plot_parameter('NW', tx_one_time['2m_temperature'], color='red')\n",
    "stationplot.plot_parameter('SW', tx_one_time['dewpoint'], color='green')\n",
    "stationplot.plot_barb(tx_u, tx_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an informative plot, but is rather crowded. Using MetPy's `reduce_point_density` function, try cleaning up this plot to something that would be presentable/publishable. This function will return a mask, which you'll apply to all arrays in the plotting commands to filter down the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oklahoma\n",
    "xy = proj.transform_points(ccrs.PlateCarree(), ok_data['LON'].values, ok_data['LAT'].values)\n",
    "# Reduce point density so that there's only one point within a 50km circle\n",
    "ok_mask = mpcalc.reduce_point_density(xy, 50000)\n",
    "\n",
    "# Texas\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# Plot\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/reduce_and_plot.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"timeseries\"></a>\n",
    "# Creating Time Series for Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to take data from all times from a single station to make a time series (or meteogram) plot? How can we easily do that with Pandas without having to aggregate the data by hand? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select daylight hours\n",
    "tx_daytime = tx_data[(tx_data['Time'] >= 600) & (tx_data['Time'] <= 2000)]\n",
    "\n",
    "# Create sub-tables for each station\n",
    "tx_grp = tx_daytime.groupby('ID')\n",
    "\n",
    "# Get data from station DIMM\n",
    "station_data = tx_grp.get_group('DIMM')\n",
    "\n",
    "# Create hourly averaged data\n",
    "time_bins = pd.cut(station_data['Time'], np.arange(600, 2100, 100))\n",
    "# xarray has groupby_bins, but pandas has cut\n",
    "station_hourly = station_data.groupby(time_bins)\n",
    "station_hourly_mean = station_hourly.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the data above to make a time series plot of the instantaneous data and the hourly averaged data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/mesonet_timeseries.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
